{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPAM Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Varvara Yakovleva\n",
    "\n",
    "* Procedure\n",
    "    * Divide data in train and test sets\n",
    "    * Keep test data in a safe!\n",
    "    * Transform test data (normalize, discretize, etc)\n",
    "    * Train model\n",
    "    * Transform test data with the parameters found in step 3\n",
    "    * Test model with test data\n",
    "    * Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metric\n",
    "s import confusion_matrix\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps easiest way to read in data is using Pandas. \n",
    "Pandas is a library for manipulating data. Similar to R's dataframes and very useful albeit in some cases confusing to combine with other libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spambase.data.txt\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This data does not have headers so each attribute or field is simply enumerated\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few ways to split data into train and test. The first is using Sklearn, which is a machine learning library in python has a method for spliting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here df.columns is a list of all the columns and df.columns[0:-1] is all columns minus the last which is y. \n",
    "# If the data had headers you could use column names: df[['column1','column2','etc']]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[df.columns[0:-1]],df[df.columns[-1]], train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something important to note. Sklearn is able to take in pandas dataframes but returns arrays "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way to split data that is useful to know is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index for selecting data 0.75 is the percentage in training\n",
    "index=np.array([1 if random() < 0.75 else 0 for i in range(len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate both train and test as well as the response variable\n",
    "X_train=np.array(df[df.columns[0:-1]])[index==1]\n",
    "X_test=np.array(df[df.columns[0:-1]])[index==0]\n",
    "Y_train=np.array(df[df.columns[-1]])[index==1]\n",
    "Y_test=np.array(df[df.columns[-1]])[index==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method for spliting data can also be used for selecting a subset of an array using the values of an equally sized array. Useful for the current excercise. For example, to extract all instances of spam for the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizar no ayuda mucho pero sale igual al de sklearn. Para que las alturas del pdf signifiquen lo mismo \n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find means and standard deviation\n",
    "spam_mean = np.mean(X_train[Y_train==1], axis=0)\n",
    "spam_std = np.std(X_train[Y_train==1], axis=0)\n",
    "\n",
    "not_spam_mean = np.mean(X_train[Y_train==0], axis=0)\n",
    "not_spam_std = np.std(X_train[Y_train==0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.394325419803\n",
      "0.605674580197\n"
     ]
    }
   ],
   "source": [
    "# Probability that message is spam or not \n",
    "pr_spam = float(sum(Y_train))/len(Y_train)\n",
    "print(pr_spam)\n",
    "\n",
    "pr_not_spam = 1 - pr_spam\n",
    "print(pr_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bayes(X):\n",
    "    spam = 0\n",
    "    not_spam = 0\n",
    "    for i in range(0, len(X)):\n",
    "        x = i \n",
    "        \n",
    "        # y_spam = p(x_i|C), but logarithmed \n",
    "        y_spam = np.ma.log(norm(spam_mean[x], spam_std[x]).pdf(X[x]))\n",
    "        #p_spam - probability of spam, according to Bayes formula\n",
    "        p_spam = np.log(pr_spam) + y_spam.sum()\n",
    "\n",
    "        # y_not_spam = p(x_i|Â¬C), but logarithmed   \n",
    "        y_not_spam = np.ma.log(norm(not_spam_mean[x], not_spam_std[x]).pdf(X[x]))\n",
    "        p_not_spam = np.log(pr_not_spam) + y_not_spam.sum()\n",
    "\n",
    "        if p_spam >= p_not_spam:\n",
    "            spam += 1\n",
    "        else:\n",
    "            not_spam += 1\n",
    "        \n",
    "    if spam > not_spam:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"not spam\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203\n",
      "2251\n"
     ]
    }
   ],
   "source": [
    "spams = 0\n",
    "not_spams = 0\n",
    "for i in range(0, len(X_train)):\n",
    "    result = bayes(X_train[i])\n",
    "    if result == \"spam\":\n",
    "        spams += 1\n",
    "    else:\n",
    "        not_spams +=1\n",
    "        \n",
    "print spams\n",
    "print not_spams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
